---
title: "Skrypty geoprzetwarzania"
subtitle: "Klasteryzacja danych"
author: "Krzysztof Dyba"
format:
  html:
    toc: true
    toc-title: " "
    embed-resources: true
    code-links:
      - text: Repozytorium
        icon: github
        href: https://github.com/kadyb/sg2025
---

```{r}
#| message: false

library("terra")
library("rstac")
options(timeout = 600)
```

# Pozyskanie danych

Niniejszą analizę wykonamy na podstawie danych z Sentinela-2. Jako źródło danych
wykorzystamy katalog STAC i usługę [Earth Search](https://element84.com/earth-search/).
Przeprowadzimy również proste filtrowanie dostępnych produktów definiując w
zapytaniu: kolekcję (`collections`), zakres przestrzenny w układzie WGS 84
(`bbox`), interwał czasowy w standardzie RFC 3339 (`datetime`) oraz atrybut
zachmurzenia sceny (`eo:cloud_cover`).

```{r}
stac_source = stac("https://earth-search.aws.element84.com/v1")
stac_source |>
  stac_search(
    collections = "sentinel-2-c1-l2a",
    bbox = c(22.5, 51.1, 22.6, 51.2),
    datetime = "2023-03-01T00:00:00Z/2023-10-31T00:00:00Z") |>
  ext_query(`eo:cloud_cover` < 10) |>
  post_request() -> obrazy
```

Jako wynik zapytania zostały zwrócone metadane scen spełniające zadane warunki.
Następnie możemy wybrać przykładową scenę z 21 września 2023 r. oraz ograniczyć
liczbę kanałów do czterech podstawowych w rozdzielczości 10 m, tj. niebieskiego,
zielonego, czerwonego i bliskiej podczerwieni w celu uproszczenia analizy.
Finalnie, używając funkcji `assets_url()` zostaną zwrócone odpowiednie odnośniki
do pobrania rastrów.

```{r}
kanaly = c("blue", "green", "red", "nir")
```

```{r}
obrazy |>
  items_filter(properties$`s2:tile_id` == "S2A_OPER_MSI_L2A_TL_2APS_20230921T151458_A043076_T34UEB_N05.09") |>
  assets_select(asset_names = kanaly) |>
  assets_url() -> sentinel
sentinel
```

Zauważ, że kanał 8 (bliska podczerwień) jest przed kanałem 4 (czerwony).
Należy mieć na uwadze, że nieodpowiednia kolejność może spowodować problemy
w dalszej części projektu.

W kolejnym kroku, używając funkcji `dir.create()` stworzymy nowy katalog na
dysku, do którego zostaną pobrane zobrazowania. Oprócz tego, należy zdefiniować
ścieżki i nazwy plików. W tym celu będą przydatne dwie funkcje -- `file.path()`
do stworzenia ścieżek do plików oraz `basename()` do wyodrębnienia nazwy
pliku wraz z rozszerzeniem z URL.

```{r}
#| eval: false
dir.create("sentinel")
rastry = file.path("sentinel", basename(sentinel))
```

Teraz możemy pobrać nasze dane używając funkcji `download.file()` w pętli.

```{r}
#| eval: false
for (i in seq_along(sentinel)) {
  download.file(sentinel[i], rastry[i], mode = "wb")
}
```

# Przygotowanie danych

Po pobraniu danych musimy stworzyć listę plików (rastrów), które zamierzamy
wczytać. W tym celu możemy wykorzystać funkcję `list.files()`, która jako
argument przyjmuje ścieżkę do folderu z plikami. Oprócz tego musimy wskazać
jaki rodzaj plików chcemy wczytać `(pattern = "\\.tif$")` oraz zwrócić pełne
ścieżki do plików `(full.names = TRUE)`.

```{r}
rastry = list.files("sentinel", pattern = "\\.tif$", full.names = TRUE)
rastry
```

Kiedy utworzyliśmy już listę plików, możemy je wczytać za pomocą funkcji
`rast()`. Pobrane zobrazowania pokrywają duży obszar (około 12 000 km$^2$).
Dla uproszczenia analizy zdefiniujmy mniejszy zakres przestrzenny do wczytania
używając funkcji `ext()` oraz przekazując obiekt SpatExtent jako argument `win`
w funkcji `rast()`.

Zwróć uwagę, że do zdefiniowania zakresu przestrzennego podczas wyszukiwania
danych użyliśmy układu WGS 84, natomiast teraz wymagany jest rzeczywisty układ
rastra, tj. `EPSG:32634`. Można to sprawdzić w metadanych katalogu STAC (obiekt
`obrazy`) lub używając funkcji `describe()` (wymaga ścieżki do pliku).

```{r}
bbox = ext(510000, 540000, 5630000, 5650000)
r = rast(rastry, win = bbox)
```

Możemy również zmienić nazwy kanałów spektralnych. Przed tą operacją należy się
upewnić czy kanały zostały wczytane w prawidłowej kolejności.

```{r}
names(r) = kanaly
r
```

Następnie możemy sprawdzić podstawowe statystyki opisowe używając funkcji
`summary()`. W przypadku dużych rastrów, zostanie automatycznie wykorzystana
próba 100 tys. komórek.

```{r}
summary(r)
```

Zasadniczo, wartości odbicia spektralnego mieszczą się w przedziale od 0 do 1,
gdzie 0 oznacza brak odbicia (całe światło zostało pochłonięte), a 1 oznacza
całkowite odbicie od powierzchni. W praktyce obiekty nie odbijają bądź
pochłaniają stuprocentowo światła, niemniej sensory oraz procesy kalibracyjne
nie są idealne, więc mogą pojawić się wartości odstające od tego przedziału,
tak jak w tej sytuacji.

Można ten problem rozwiązać na dwa sposoby:

1. Zastąpić te wartości brakiem danych (`NA`).
2. Dociąć do minimalnej i maksymalnej wartości.

Pierwszy sposób może spowodować, że stracimy dużą część zbioru danych.
Natomiast drugi sposób może powodować przekłamania.

```{r}
# sposób 1
r = clamp(r, lower = 0, upper = 1, values = FALSE)
```

```{r eval=FALSE}
# sposób 2
r = clamp(r, lower = 0, upper = 1, values = TRUE)
```

Po przeskalowaniu wartości możemy wyświetlić kompozycję RGB. W tym przypadku
zamiast funkcji `plot()` należy użyć funkcji `plotRGB()` oraz zdefiniować 
kolejność kanałów czerwonego, zielonego oraz niebieskiego. Często zdarza się,
że kompozycje są zbyt ciemne/jasne, wtedy warto zastosować rozciągnięcie kolorów
używając argumentu `stretch = "lin"` lub `stretch = "hist"`.

```{r}
# plotRGB(r, r = 3, g = 2, b = 1)
plotRGB(r, r = 3, g = 2, b = 1, stretch = "lin")
```

# Klasteryzacja

```{r}
library("cluster") # klasteryzacja danych
```

Dane do modelowania muszą zostać przygotowane w odpowiedni sposób. Modele
klasyfikacyjne najczęściej na etapie trenowania wymagają macierzy lub ramki
danych (*data frame*). Dane rastrowe można przetworzyć do macierzy przy użyciu
funkcji `values()`.

```{r}
mat = values(r)
nrow(mat) # wyświetla liczbę wierszy
```

Za pomocą interaktywnej funkcji `View()` możemy sprawdzić jak wygląda nasza macierz.

```{r eval=FALSE}
View(mat)
```

W macierzy występują brakujące wartości. Zazwyczaj modele nie obsługują
`NA`, więc musimy je usunąć. Służy do tego dedykowana funkcja `na.omit()`.

```{r}
mat_omit = na.omit(mat)
nrow(mat_omit)
```

Teraz przejdziemy do kolejnego etapu analizy, jakim jest wytrenowanie modelu.
Istnieje wiele metod i modeli grupowania (patrz [CRAN Task View](https://cran.r-project.org/web/views/Cluster.html)),
ale w tym przykładzie użyjemy prostego modelu [grupowania metodą k-średnich](https://www.statsoft.pl/textbook/stcluan.html#k).
Ten model wymaga jedynie, aby podać z góry liczbę grup/klastrów
(argument `centers`). Jest to algorytm stochastyczny, więc za każdym razem
zwraca inne wyniki. Żeby analiza była powtarzalna musimy ustawić ziarno
losowości -- `set.seed()`.

```{r}
set.seed(123) # ziarno losowości
mdl = kmeans(mat_omit, centers = 3)
```

W wyniku powyższej operacji otrzymaliśmy m.in.:

1. Obliczone średnie wartości grup dla poszczególnych kanałów (`mdl$centers`).
2. Wektor ze sklasyfikowanymi wartościami macierzy (`mdl$cluster`).

Wyświetlmy te obiekty:

```{r}
mdl$centers
```

```{r}
head(mdl$cluster)
```

Oznacza to, że pierwszy wiersz (reprezentujący pojedyncze oczko siatki) należy
do grupy 2, drugi do grupy 2, trzeci do grupy 2, itd.

# Walidacja

Nieodłącznym elementem modelowania jest walidacja opracowanych modeli. Wyzwaniem
jest wybór właściwej metody grupowania dla konkretnego zbioru danych i określenie
odpowiedniej liczby grup. Należy pamiętać, że zwiększenie liczby klastrów
zwiększa podobieństwo między obiektami w klastrze, ale przy ich większej liczbie
interpretacja staje się trudniejsza.

Najczęstszym sposobem walidacji wyników grupowania jest użycie wewnętrznych
metryk, takich jak wskaźnik Dunna, wskaźnik Daviesa-Bouldina lub wskaźnik
sylwetki (*silhouette index*). Na potrzebny niniejszej analizy użyjemy tego
ostatniego.

Indeks sylwetki ocenia zbieżność i separację klastrów na podstawie odległości
między obiektami w tym samym klastrze i między obiektami w różnych klastrach.
Wartości tego wskaźnika mieszczą się w zakresie od -1 do 1. Wartość bliska 1
wskazuje, że obiekt jest dobrze zgrupowany i znajduje się daleko od sąsiednich
klastrów. Wartość bliska -1 sugeruje, że obiekt mógł zostać przypisany do
niewłaściwego klastra. Wartość bliska 0 wskazuje, że obiekt znajduje się bardzo
blisko granicy pomiędzy różnymi klastrami. Ogólnie rzecz biorąc, wyższa wartość
tego wskaźnika wskazuje na lepsze wyniki grupowania. Więcej szczegółów można
znaleźć w dokumentacji `cluster::silhouette()`.

Spróbujmy teraz obliczyć wartości tego wskaźnika. Zasadniczo wymaga to obliczenie
podobieństwa każdego obiektu do każdego obiektu, co w naszym przypadku jest
zadaniem niemożliwym (nasz zbiór danych składa się z ponad 6 mln obiektów).
Aby to wykonać, musimy wykorzystać mniejszą próbkę (załóżmy $n=10000$).
W funkcji musimy określić dwa obiekty –- wektor z klastrami oraz macierz
niepodobieństwa, którą można wcześniej obliczyć za pomocą funkcji `dist()`.

```{r}
set.seed(123)
# losowanie indeksów
idx = sample(1:nrow(mat_omit), size = 10000)
head(idx)
```

```{r}
# obliczenie wskaźnika sylwetki
sil = silhouette(mdl$cluster[idx], dist(mat_omit[idx, ]))
summary(sil)
```

Średnia zbieżność klastrów wynosi 0,44. Nie jest to najlepszy wynik (powinniśmy
spróbować zwiększyć liczbę klastrów lub użyć innej metody grupowania). Możemy
również zaprezentować wyniki na wykresie.

```{r}
kolory = rainbow(3) # wybierz 3 kolory z wbudowanej palety `rainbow`
plot(sil, border = NA, col = kolory, main = "Silhouette Index")
```

# Interpretacja

Istotą grupowania jest utworzenie grupy podobnych obiektów, natomiast naszym
zadaniem jest zinterpretowanie tego, co reprezentują utworzone grupy i nadanie
im nazwy. Interpretacja jest trudnym zadaniem i często wyniki są niejasne.
W tym celu konieczne jest przeanalizowanie statystyk opisowych klastrów oraz
wykorzystanie różnych wykresów i kompozycji map. Bardzo przydatna jest także
znajomość właściwości spektralnych obiektów.

Spróbujmy zatem zinterpretować uzyskane skupienia, korzystając z wykresu
pudełkowego. Największe możliwości wizualizacji danych dostarcza pakiet
**ggplot2**. Tutaj można znaleźć darmowy [podręcznik](https://ggplot2-book.org/)
oraz gotowe ["przepisy"](https://r-graphics.org/). Wymieniony pakiet wymaga
przygotowania zbioru danych do odpowiedniej postaci, tj. dane muszą być
przedstawione jako ramka danych w tzw. formie długiej (wiele wierszy), podczas
gdy standardowe funkcje do wizualizacji wymagają formy szerokiej (wiele kolumn).
Takiej konwersji można dokonać w prosty sposób używając pakietu **tidyr**.

```{r}
#| message: false

library("tidyr") # transformacja danych
library("ggplot2") # wizualizacja danych
```

Jak zauważyliśmy wcześniej, nasz zbiór danych jest dość duży i nie ma potrzeby
prezentowania wszystkich danych. Możemy to zrobić efektywniej, używając wcześniej
wylosowanej próby. Połączmy zatem wylosowane wiersze z macierzy z odpowiadającymi
im klastrami (`cbind()`). Następnie macierz zamienimy na ramkę danych
(`as.data.frame()`).

```{r}
stats = cbind(mat_omit[idx, ], klaster = mdl$cluster[idx])
stats = as.data.frame(stats)
head(stats)
```

Wyświetlone dane mają formę szeroką (każdy kanał spektralny zapisany jest
w osobnej kolumnie). Teraz musimy zmienić formę, w której otrzymamy dwie
kolumn -- kanał oraz wartość. W tym celu wykorzystamy funkcję `pivot_longer()`.

```{r}
stats = pivot_longer(stats, cols = 1:4, names_to = "kanal", values_to = "wartosc")
```

Dla formalności możemy jeszcze zmienić typ danych (klastrów i kanałów) na
kategoryczny (*factor*). W praktyce związane jest to z uproszczeniem struktury
danych (przejście ze skali ilorazowej do nominalnej).

```{r}
stats$klaster = factor(stats$klaster)
stats$kanal = factor(stats$kanal)
head(stats)
```

Ramka danych jest już przygotowana. Teraz stwórzmy prosty wykres pudełkowy.

```{r}
ggplot(stats, aes(x = kanal, y = wartosc, fill = klaster)) +
  geom_boxplot()
```

Zmieńmy kilka domyślnych parametrów żeby poprawić odbiór ryciny.

```{r}
etykiety = c("Niebieski", "Zielony", "Czerwony", "Bliska\npodczerwień")

ggplot(stats, aes(x = kanal, y = wartosc, fill = klaster)) +
  geom_boxplot(show.legend = FALSE) +
  scale_x_discrete(limits = kanaly, labels = etykiety) +
  scale_fill_manual(values = kolory) +
  facet_wrap(vars(klaster)) +
  xlab("Kanał") +
  ylab("Odbicie") +
  theme_light()
```

Na podstawie powyższego wykresu możemy przeanalizować właściwości spektralne
klastrów, a tym samym zinterpretować, jakie obiekty reprezentują.

# Finalna mapa

Ostatnim etapem jest stworzenie mapy klasyfikacyjnej pokrycia terenu na podstawie
otrzymanego wektora z klastrami (`mdl$cluster`). Na początku musimy przygotować
pusty wektor składający się z całkowitej liczby komórek rastra. Można to
sprawdzić za pomocą funkcji `ncell()`. W naszym przypadku jest to 6 milionów
komórek.

```{r}
# przygotuj pusty wektor
wek = rep(NA, ncell(r))
```

Następnie musimy przypisać nasze grupy w wektorze w odpowiednie miejsca,
tj. tym, które nie są zamaskowane (`NA`). Do niezamaskowanych
wartości można odwołać się przez funkcję `complete.cases()`. 

```{r}
# zastąp tylko te wartości, które nie są NA
wek[complete.cases(mat)] = mdl$cluster 
```

W ostatnim kroku należy skopiować metadane obiektu `r`, ale tylko z jedną
warstwą, i przypisać mu wartości wektora `wek`.

```{r}
# stwórz nowy raster
clustering = rast(r, nlyrs = 1, vals = wek)
```

Zaprezentujmy wynik grupowania na mapie, używając odpowiednich kolorów i nazw
klastrów.

```{r}
kolory = c("#d9d9d9", "#086209", "#2fbd2f")
kategorie = c("odkryta gleba", "lasy/woda", "roślinność")
plot(clustering, col = kolory, type = "classes", levels = kategorie,
     mar = c(3, 3, 3, 7))
```

Jeśli wynik jest zadowalający, możemy zapisać go za pomocą funkcji
`writeRaster()`. Taki plik można później wczytać w **R** lub innym programie
obsługującym dane przestrzenne (np. **QGIS**). Dodatkowo, w przypadku danych
kategorycznych, podczas zapisu warto ustawić typ danych jako `Byte` / `INT1U`
(pod warunkiem, że liczba kategorii nie przekracza 255).

```{r}
#| eval: false
writeRaster(clustering, "clustering.tif", datatype = "INT1U")
```

# Zadanie

**7.** Pobierz scenę satelitarną o niskim zachmurzeniu i dotnij jej zasięg
do wybranego powiatu. Wykonaj klasteryzację metodą kmeans oraz [inną wybraną](https://www.datacamp.com/doc/r/cluster).
Następnie dokonaj walidacji otrzymanych wyników wykorzystując wskaźnik
*silhouette*. Przygotuj również wykres pudełkowy przedstawiający zmienność
powstałych klastrów. Finalnie, zaprezentuj wynik klasteryzacji na mapie (dobierz
odpowiedni schemat kolorów) oraz kompozycję RGB.
